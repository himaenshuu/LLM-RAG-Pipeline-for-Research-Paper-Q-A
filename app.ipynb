{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c074b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet langchain-text-splitters langchain-community langgraph \n",
    "%pip install -q \"langchain[google-genai]\"\n",
    "%pip install -q langchain langchain-google-genai google-generativeai\n",
    "%pip install -q langchain-chroma\n",
    "%pip install -q beautifulsoup4\n",
    "%pip install -q pypdf\n",
    "%pip install -q langchain_community pypdf\n",
    "%pip install -qU langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd54c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11471cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's great to be able to interact with you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Securely input and set API key\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API\")\n",
    "\n",
    "# Initialize Gemini 2.0 Flash model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
    ")\n",
    "\n",
    "# Example call\n",
    "response = llm.invoke([HumanMessage(content=\"Hello Gemini 2.0!\")])\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f500270",
   "metadata": {},
   "source": [
    "## Efficient handling of the response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0afdc694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response:\n",
      " AI, while holding immense potential for good, also presents several potential disaster scenarios. These can be broadly categorized as follows:\n",
      "Job Displacement and Economic Instability:\n",
      "\n",
      "   Mass Unemployment: AI-powered automation could displace workers across various industries, leading to mass unemployment, increased inequality, and social unrest.\n",
      "   Deskilling:  AI might take over complex tasks, leading to a decline in human skills and making workers more vulnerable to job losses.\n",
      "   Concentration of Wealth: The benefits of AI could be concentrated in the hands of a few companies and individuals, further exacerbating wealth inequality.\n",
      "Bias and Discrimination:\n",
      "\n",
      "   Reinforcement of Existing Biases: AI systems are trained on data, and if that data reflects existing societal biases (e.g., racial, gender), the AI will perpetuate and even amplify those biases in its decision-making. This can lead to unfair outcomes in areas like hiring, loan applications, criminal justice, and healthcare.\n",
      "   Algorithmic Discrimination: Even without explicit bias in the data, AI algorithms can learn to discriminate based on subtle correlations, leading to unintended but harmful consequences.\n",
      "   Lack of Transparency and Accountability:  The \"black box\" nature of some AI systems makes it difficult to understand why they make certain decisions, making it challenging to identify and correct biases.\n",
      "Security Risks and Malicious Use:\n",
      "\n",
      "   Autonomous Weapons Systems (AWS): AI-powered weapons could make life-or-death decisions without human intervention, raising ethical concerns about accountability, unintended consequences, and the potential for accidental escalation of conflicts.\n",
      "   Cyberattacks: AI could be used to develop more sophisticated and effective cyberattacks, making it harder to defend against them.\n",
      "   Deepfakes and Misinformation: AI can create realistic fake videos and audio, which could be used to spread misinformation, manipulate public opinion, and damage reputations.\n",
      "   Surveillance and Privacy Violations: AI-powered surveillance systems could be used to track and monitor individuals, leading to privacy violations and potentially chilling effects on freedom of expression.\n",
      "   Erosion of Trust:  The prevalence of AI-generated content and the potential for manipulation could erode trust in information and institutions.\n",
      "Unintended Consequences and Lack of Control:\n",
      "\n",
      "   Goal Misalignment:  AI systems may optimize for goals that are not perfectly aligned with human values, leading to unintended and undesirable outcomes.  For example, an AI designed to maximize efficiency in a factory might do so at the expense of worker safety.\n",
      "   Unpredictable Behavior:  Complex AI systems can exhibit emergent behaviors that are difficult to predict or control, potentially leading to unforeseen and harmful consequences.\n",
      "   Loss of Human Control:  As AI systems become more autonomous, humans may lose the ability to effectively control them, leading to a situation where AI is making decisions that are not in our best interests.\n",
      "   Runaway AI:  In extreme scenarios, a superintelligent AI could become uncontrollable and pose an existential threat to humanity.  This is a highly speculative but potentially catastrophic risk.\n",
      "Social and Political Instability:\n",
      "\n",
      "   Erosion of Democracy: AI-powered propaganda and manipulation could undermine democratic processes and institutions.\n",
      "   Increased Polarization: AI algorithms could create filter bubbles and echo chambers, reinforcing existing biases and making it harder for people to engage in constructive dialogue.\n",
      "   Authoritarian Control:  AI could be used to enhance the power of authoritarian regimes, enabling them to suppress dissent and control their populations more effectively.\n",
      "Infrastructure Vulnerabilities:\n",
      "\n",
      "   Dependence and Single Points of Failure: Over-reliance on AI systems could create vulnerabilities in critical infrastructure, making it susceptible to disruption or collapse in the event of a system failure or attack.\n",
      "   Complexity and Opacity: The complexity of AI systems can make them difficult to understand and maintain, increasing the risk of errors and failures.\n",
      "\n",
      "Mitigation Strategies:\n",
      "\n",
      "It is important to note that these potential disasters are not inevitable.  By taking proactive steps, we can mitigate the risks and harness the benefits of AI.  Some key strategies include:\n",
      "\n",
      "   Developing ethical guidelines and regulations:  Establishing clear ethical principles and legal frameworks for AI development and deployment.\n",
      "   Promoting transparency and explainability:  Developing AI systems that are transparent and explainable, so that we can understand how they make decisions.\n",
      "   Investing in education and retraining:  Preparing the workforce for the changing job market by investing in education and retraining programs.\n",
      "   Addressing bias in data and algorithms:  Developing techniques to identify and mitigate bias in AI systems.\n",
      "   Promoting diversity and inclusion:  Ensuring that AI development teams are diverse and inclusive, so that different perspectives are considered.\n",
      "   Investing in AI safety research:  Conducting research to understand and mitigate the risks of AI.\n",
      "   Fostering international cooperation:  Working with other countries to develop common standards and regulations for AI.\n",
      "   Promoting public awareness:  Educating the public about the potential benefits and risks of AI.\n",
      "   Human Oversight and Control:  Maintaining appropriate human oversight and control over critical AI systems.\n",
      "\n",
      "By carefully considering these potential risks and taking proactive steps to mitigate them, we can ensure that AI is used for the benefit of humanity. The key is to be aware, be proactive, and prioritize human well-being and ethical considerations in the development and deployment of AI.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def clean_llm_response(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.replace(\"*\", \"\")  # Remove asterisks\n",
    "    text = re.sub(r\"^#+\\s?\", \"\", text, flags=re.MULTILINE)  # Remove markdown headers\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)  # Normalize blank lines\n",
    "    text = re.sub(r\"^\\s*[-‚Ä¢\\d]+\\.\\s+\", \"\", text, flags=re.MULTILINE)  # Clean bullet prefixes\n",
    "    text = html.unescape(text)  # Decode &amp;, &lt;, &gt;, etc.\n",
    "    text = text.replace(\"```\", \"\")  # Remove code block markers\n",
    "    text = text.replace(\"‚Äú\", '\"').replace(\"‚Äù\", '\"')  # Normalize double quotes\n",
    "    text = text.replace(\"‚Äò\", \"'\").replace(\"‚Äô\", \"'\")  # Normalize single quotes\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# === Main invocation ===\n",
    "user_input = input(\"You: \")\n",
    "response = llm.invoke([HumanMessage(content=user_input)])\n",
    "cleaned_output = clean_llm_response(response.content)\n",
    "print(\"\\nLLM Response:\\n\", cleaned_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model and setup\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API\")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "588d15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create the collection before using it\n",
    "if not client.collection_exists(collection_name=\"test\"):\n",
    "    client.create_collection(\n",
    "        collection_name=\"test\",\n",
    "        vectors_config={\"size\": embeddings.embed_query(\"test\").__len__(), \"distance\": \"Cosine\"}\n",
    "    )\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"test\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93bee1",
   "metadata": {},
   "source": [
    "## Web Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93fb3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94191d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# url = input(\"Enter the URL to load: \").strip()  //for run time user input\n",
    "loader = WebBaseLoader(\n",
    "    web_paths= (\"https://en.wikipedia.org/wiki/Formula_One_car\",),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# more chunks more specific \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks only if there is content\n",
    "if all_splits:\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "else:\n",
    "    print(\"Warning: No content was loaded or split from the web page. Skipping indexing.\")\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "030109d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An F1 car, or Formula One car, is a single-seat, open-cockpit, open-wheel racing car used in Formula One racing events. It features front and rear wings, large wheels, and a turbocharged engine behind the driver. These cars are constructed with carbon fiber and composite materials to withstand high impact forces.\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \") \n",
    "response = graph.invoke({\"question\": question})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435119e3",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7670b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document processed and indexed for RAG.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "async def process_pdf_async(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    # pages = loader.load()\n",
    "    \n",
    "    # Load pages asynchronously suitable for larger pdfs or while using lazy load\n",
    "    pages = []\n",
    "    async for page in loader.alazy_load():\n",
    "        # Optional: clean page content to avoid Unicode issues\n",
    "        page.page_content = page.page_content.encode(\"utf-8\", \"ignore\").decode(\"utf-8\")\n",
    "        pages.append(page)\n",
    "\n",
    "    # Split text into chunks\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = splitter.split_documents(pages)\n",
    "     \n",
    "    # Create the collection before using it\n",
    "    if not client.collection_exists(collection_name=\"test1\"):\n",
    "        client.create_collection(\n",
    "        collection_name=\"test1\",\n",
    "        vectors_config={\"size\": embeddings.embed_query(\"test1\").__len__(), \"distance\": \"Cosine\"}\n",
    "        )\n",
    "\n",
    "    vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"test1\",\n",
    "    embedding=embeddings,\n",
    "    )\n",
    "\n",
    "    if splits:\n",
    "        vector_store.add_documents(splits)\n",
    "        print(\"Document processed and indexed for RAG.\")\n",
    "    else:\n",
    "        print(\" No content extracted from PDF.\")\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "file_path = \"f1car.pdf\"\n",
    "vector_store = await process_pdf_async(file_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59b92c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Response:\n",
      " Here's a summary of the steering and transmission of Formula One cars, based on the provided text:\n",
      "\n",
      "   Gearboxes: Modern F1 cars use semi-automatic sequential gearboxes with rear-wheel drive. These have eight forward gears and a reverse gear, operated by paddle shifters.\n",
      "   Materials: The gearbox is constructed from carbon-reinforced titanium and is bolted to the back of the engine.\n",
      "   Automation Ban: Fully automatic gearboxes, launch control, and traction control were banned in the 2000s to emphasize driver skill and reduce costs.\n",
      "   Gear Shifts: Gear shifts are initiated by the driver using paddles on the steering wheel. A system of solenoids, hydraulic actuators, and sensors then performs the shift.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "question = \"comment on the steering and transmission of f1 cars\"\n",
    "\n",
    "results = vector_store.similarity_search(question, k=3)\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in results)\n",
    "\n",
    "prompt = f\"\"\"Answer the question based on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke([HumanMessage(content=prompt)])\n",
    "# print(\"Answer:\\n\",response.content)\n",
    "cleaned_output = clean_llm_response(response.content)\n",
    "print(\"\\nLLM Response:\\n\", cleaned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117273c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "179657bb",
   "metadata": {},
   "source": [
    "## RAG for Academic papers using grobid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7591b190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To know more about grobid look at Readme file\n",
    "\n",
    "# Check if grobid is alive\n",
    "import requests\n",
    "requests.get(\"http://localhost:8070/api/isalive\").text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 46 structured docs\n",
      "{'text': 'The promise of deep learning is to discover rich, hierarchical models [2] that represent probability distributions over the kinds of data encountered in artificial intelligence applications, such as natural images, audio waveforms containing speech, and symbols in natural language corpora.So far, the most striking successes in deep learning have involved discriminative models, usually those that map a high-dimensional, rich sensory input to a class label [14,22].These striking successes have primarily been based on the backpropagation and dropout algorithms, using piecewise linear units [19,9,10] which have a particularly well-behaved gradient .Deep generative models have had less of an impact, due to the difficulty of approximating many intractable probabilistic computations that arise in maximum likelihood estimation and related strategies, and due to difficulty of leveraging the benefits of piecewise linear units in the generative context.We propose a new generative model estimation procedure that sidesteps these difficulties. 1  In the proposed adversarial nets framework, the generative model is pitted against an adversary: a discriminative model that learns to determine whether a sample is from the model distribution or the data distribution.The generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency.Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.', 'para': '7', 'bboxes': \"[[{'page': '1', 'x': '108.00', 'y': '477.13', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '488.09', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '499.05', 'h': '349.84', 'w': '8.64'}], [{'page': '1', 'x': '462.27', 'y': '499.05', 'h': '41.73', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '510.01', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '520.97', 'h': '273.01', 'w': '8.64'}], [{'page': '1', 'x': '384.87', 'y': '520.97', 'h': '119.13', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '531.93', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '542.88', 'h': '240.83', 'w': '8.64'}], [{'page': '1', 'x': '352.00', 'y': '542.71', 'h': '152.00', 'w': '8.82'}, {'page': '1', 'x': '108.00', 'y': '553.84', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '564.80', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '575.76', 'h': '248.44', 'w': '8.64'}], [{'page': '1', 'x': '359.77', 'y': '575.76', 'h': '144.23', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '586.72', 'h': '210.05', 'w': '8.64'}, {'page': '1', 'x': '321.14', 'y': '585.05', 'h': '3.49', 'w': '6.05'}], [{'page': '1', 'x': '108.00', 'y': '603.48', 'h': '396.00', 'w': '8.82'}, {'page': '1', 'x': '108.00', 'y': '614.62', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '625.57', 'h': '67.56', 'w': '8.64'}], [{'page': '1', 'x': '179.34', 'y': '625.57', 'h': '324.66', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '636.53', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '647.49', 'h': '261.75', 'w': '8.64'}], [{'page': '1', 'x': '374.45', 'y': '647.49', 'h': '129.55', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '658.45', 'h': '396.00', 'w': '8.64'}, {'page': '1', 'x': '108.00', 'y': '669.41', 'h': '31.26', 'w': '8.64'}]]\", 'pages': \"('1', '1')\", 'section_title': 'Introduction', 'section_number': '1', 'paper_title': 'Generative Adversarial Nets', 'file_path': 'research_paper\\\\gan.pdf'}\n",
      "The promise of deep learning is to discover rich, hierarchical models [2] that represent probability distributions over the kinds of data encountered in artificial intelligence applications, such as natural images, audio waveforms containing speech, and symbols in natural language corpora.So far, the most striking successes in deep learning have involved discriminative models, usually those that map a high-dimensional, rich sensory input to a class label [14,22].These striking successes have pri\n"
     ]
    }
   ],
   "source": [
    "# Loader using Grobid which is runnning on the machine\n",
    "# Look on the readme file to setup grobid\n",
    "\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import GrobidParser\n",
    "\n",
    "# Load PDFs from a folder using GROBID\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    \"research_paper/\",\n",
    "    glob=\"*\",\n",
    "    suffixes=[\".pdf\"],\n",
    "    parser=GrobidParser(segment_sentences=False)\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"‚úÖ Loaded {len(docs)} structured docs\")\n",
    "print(docs[0].metadata)\n",
    "print(docs[0].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18a001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split into 50 chunks\n"
     ]
    }
   ],
   "source": [
    "# Splitter\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = splitter.split_documents(docs)\n",
    "\n",
    "print(f\"‚úÖ Split into {len(splits)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05169466",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e638a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunks embedded and stored in Qdrant DB\n"
     ]
    }
   ],
   "source": [
    "# Embedder\n",
    "\n",
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "# Create the collection before using it\n",
    "if not client.collection_exists(collection_name=\"test3\"):\n",
    "    dim = len(embeddings.embed_query(\"test3\"))  # Get embedding vector size\n",
    "\n",
    "    client.create_collection(\n",
    "        collection_name=\"test3\",\n",
    "        vectors_config=VectorParams(\n",
    "            size=dim,\n",
    "            distance=Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Initialize Qdrant vector store\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"test3\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Chunks embedded and stored in Qdrant DB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690a22f",
   "metadata": {},
   "source": [
    "## Semantic search for papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9250e1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "{'text': 'We estimate probability of the test set data under p g by fitting a Gaussian Parzen window to the samples generated with G and reporting the log-likelihood under this distribution.The œÉ parameter Model MNIST TFD DBN [3] 138 ¬± 2 1909 ¬± 66 Stacked CAE [3] 121 ¬± 1.6 2110 ¬± 50 Deep GSN [6] 214 ¬± 1.1 1890 ¬± 29 Adversarial nets 225 ¬± 2 2057 ¬± 26', 'para': '1', 'bboxes': \"[[{'page': '5', 'x': '108.00', 'y': '712.10', 'h': '396.00', 'w': '9.65'}, {'page': '5', 'x': '108.00', 'y': '723.06', 'h': '326.39', 'w': '8.96'}], [{'page': '5', 'x': '437.57', 'y': '723.06', 'h': '66.43', 'w': '8.96'}, {'page': '6', 'x': '237.44', 'y': '83.05', 'h': '26.01', 'w': '8.64'}, {'page': '6', 'x': '301.21', 'y': '83.05', 'h': '30.99', 'w': '8.64'}, {'page': '6', 'x': '362.85', 'y': '83.05', 'h': '18.82', 'w': '8.64'}, {'page': '6', 'x': '232.88', 'y': '94.40', 'h': '35.14', 'w': '8.64'}, {'page': '6', 'x': '300.66', 'y': '94.09', 'h': '32.10', 'w': '8.74'}, {'page': '6', 'x': '351.23', 'y': '94.09', 'h': '42.06', 'w': '8.74'}, {'page': '6', 'x': '216.47', 'y': '105.01', 'h': '179.07', 'w': '8.99'}, {'page': '6', 'x': '221.68', 'y': '116.32', 'h': '57.54', 'w': '8.64'}, {'page': '6', 'x': '296.78', 'y': '116.00', 'h': '96.51', 'w': '8.74'}, {'page': '6', 'x': '218.01', 'y': '127.28', 'h': '64.87', 'w': '8.64'}, {'page': '6', 'x': '299.16', 'y': '126.93', 'h': '96.37', 'w': '8.77'}]]\", 'pages': \"('5', '6')\", 'section_title': 'Experiments', 'section_number': '5', 'paper_title': 'Generative Adversarial Nets', 'file_path': 'research_paper\\\\gan.pdf', '_id': '2dfc058a73294833a53ae6cdf940a723', '_collection_name': 'test3'}\n",
      "We estimate probability of the test set data under p g by fitting a Gaussian Parzen window to the samples generated with G and reporting the log-likelihood under this distribution.The œÉ parameter Model MNIST TFD DBN [3] 138 ¬± 2 1909 ¬± 66 Stacked CAE [3] 121 ¬± 1.6 2110 ¬± 50 Deep GSN [6] 214 ¬± 1.1 189 ...\n",
      "\n",
      "Result 2:\n",
      "{'text': 'We estimate probability of the test set data under p g by fitting a Gaussian Parzen window to the samples generated with G and reporting the log-likelihood under this distribution.The œÉ parameter Model MNIST TFD DBN [3] 138 ¬± 2 1909 ¬± 66 Stacked CAE [3] 121 ¬± 1.6 2110 ¬± 50 Deep GSN [6] 214 ¬± 1.1 1890 ¬± 29 Adversarial nets 225 ¬± 2 2057 ¬± 26', 'para': '1', 'bboxes': \"[[{'page': '5', 'x': '108.00', 'y': '712.10', 'h': '396.00', 'w': '9.65'}, {'page': '5', 'x': '108.00', 'y': '723.06', 'h': '326.39', 'w': '8.96'}], [{'page': '5', 'x': '437.57', 'y': '723.06', 'h': '66.43', 'w': '8.96'}, {'page': '6', 'x': '237.44', 'y': '83.05', 'h': '26.01', 'w': '8.64'}, {'page': '6', 'x': '301.21', 'y': '83.05', 'h': '30.99', 'w': '8.64'}, {'page': '6', 'x': '362.85', 'y': '83.05', 'h': '18.82', 'w': '8.64'}, {'page': '6', 'x': '232.88', 'y': '94.40', 'h': '35.14', 'w': '8.64'}, {'page': '6', 'x': '300.66', 'y': '94.09', 'h': '32.10', 'w': '8.74'}, {'page': '6', 'x': '351.23', 'y': '94.09', 'h': '42.06', 'w': '8.74'}, {'page': '6', 'x': '216.47', 'y': '105.01', 'h': '179.07', 'w': '8.99'}, {'page': '6', 'x': '221.68', 'y': '116.32', 'h': '57.54', 'w': '8.64'}, {'page': '6', 'x': '296.78', 'y': '116.00', 'h': '96.51', 'w': '8.74'}, {'page': '6', 'x': '218.01', 'y': '127.28', 'h': '64.87', 'w': '8.64'}, {'page': '6', 'x': '299.16', 'y': '126.93', 'h': '96.37', 'w': '8.77'}]]\", 'pages': \"('5', '6')\", 'section_title': 'Experiments', 'section_number': '5', 'paper_title': 'Generative Adversarial Nets', 'file_path': 'research_paper\\\\gan.pdf', '_id': 'c37d1533e54c48498d9b2b3ae2ea243b', '_collection_name': 'test3'}\n",
      "We estimate probability of the test set data under p g by fitting a Gaussian Parzen window to the samples generated with G and reporting the log-likelihood under this distribution.The œÉ parameter Model MNIST TFD DBN [3] 138 ¬± 2 1909 ¬± 66 Stacked CAE [3] 121 ¬± 1.6 2110 ¬± 50 Deep GSN [6] 214 ¬± 1.1 189 ...\n",
      "\n",
      "Result 3:\n",
      "{'text': 'Finally, some techniques do not involve defining a probability distribution explicitly, but rather train a generative machine to draw samples from the desired distribution.This approach has the advantage that such machines can be designed to be trained by back-propagation.Prominent recent work in this area includes the generative stochastic network (GSN) framework [5], which extends generalized denoising auto-encoders [4]: both can be seen as defining a parameterized Markov chain, i.e., one learns the parameters of a machine that performs one step of a generative Markov chain.Compared to GSNs, the adversarial nets framework does not require a Markov chain for sampling.Because adversarial nets do not require feedback loops during generation, they are better able to leverage piecewise linear units [19,9,10], which improve the performance of backpropagation but have problems with unbounded activation when used ina feedback loop.More recent examples of training a generative machine by back-propagating into it include recent work on auto-encoding variational Bayes [20] and stochastic backpropagation [24].', 'para': '5', 'bboxes': \"[[{'page': '2', 'x': '108.00', 'y': '468.12', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '479.08', 'h': '265.31', 'w': '8.64'}], [{'page': '2', 'x': '376.23', 'y': '479.08', 'h': '127.77', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '490.04', 'h': '276.62', 'w': '8.64'}], [{'page': '2', 'x': '387.55', 'y': '490.04', 'h': '116.45', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '501.00', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '511.95', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '522.91', 'h': '351.41', 'w': '8.64'}], [{'page': '2', 'x': '462.50', 'y': '522.91', 'h': '41.50', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '533.87', 'h': '357.69', 'w': '8.64'}], [{'page': '2', 'x': '470.81', 'y': '533.87', 'h': '33.20', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '544.83', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '555.79', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '566.75', 'h': '262.27', 'w': '8.64'}], [{'page': '2', 'x': '373.19', 'y': '566.75', 'h': '130.81', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '577.71', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '588.67', 'h': '192.52', 'w': '8.64'}]]\", 'pages': \"('2', '2')\", 'section_title': 'Related work', 'section_number': '2', 'paper_title': 'Generative Adversarial Nets', 'file_path': 'research_paper\\\\gan.pdf', '_id': '02163744dd354ebfb26905edd35aa303', '_collection_name': 'test3'}\n",
      "Finally, some techniques do not involve defining a probability distribution explicitly, but rather train a generative machine to draw samples from the desired distribution.This approach has the advantage that such machines can be designed to be trained by back-propagation.Prominent recent work in th ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"What is GAN?\"\n",
    "\n",
    "# Retrieve top-k similar chunks\n",
    "results = vector_store.similarity_search(query, k=3)  # It will return top three most similar docs\n",
    "\n",
    "# Inspect results\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content[:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e5b5b",
   "metadata": {},
   "source": [
    "## Used the Gemini to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e065e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Gemini Answer:\n",
      " Based on the provided text, GAN stands for \"adversarial nets framework.\" It's a technique that trains a generative machine to draw samples from a desired distribution without explicitly defining a probability distribution. Unlike some other methods like Generative Stochastic Networks (GSNs), GANs don't require a Markov chain for sampling, allowing them to better utilize piecewise linear units.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "# Combine the context\n",
    "context = \"\\n\\n\".join(doc.page_content for doc in results)\n",
    "\n",
    "prompt = f\"\"\"Use the following research paper content to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke([HumanMessage(content=prompt)])\n",
    "print(\"\\nüß† Gemini Answer:\\n\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d7052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
